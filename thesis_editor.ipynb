{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editor \n",
    "\n",
    "#### This is the editor interface for Christopher Speed '24's Senior Thesis!\n",
    "\n",
    "This notebook allows you to edit together a stand-up comedy special using several different editing paradigms (as explained below). \n",
    "\n",
    "It provides both fully automated and manual editing methods, and facilitates exporting a completed video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import core libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing.load import setup_editor, load_edit, load_annotations\n",
    "from editor.editor import edit_random, edit_simple, edit_complex\n",
    "from editor.video import assemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize State\n",
    "\n",
    "At times, Jupyter notebooks can be fragile, requiring that you restart the kernel and reinitialize any variables. Given that this project involves processing lengthy video and audio files for editing, face detection, and other tasks, reloading and re-processing videos any time a restart is required would be incredibly unwieldy and inefficient, wasting considerable amounts of time.\n",
    "\n",
    "To address this, we do the following to make our application *stateful* to minimize the negative impact of notebook restarts and errors:\n",
    "- Until specified, each of the Python cells in this introductory portion of the notebook should be run **in order, top-to-bottom**. This provides a correct sequence of initialization for our edit and annotation data. \n",
    "- Each of the edit functions (`edit_simple`, `edit_complex`, and `edit_random`) saves the resulting edit sequence object as a pickled file to disk by default, allowing you to simply reinitialize the edit by unpickling the file in the case that a restart is required or you prefer the previous version of an edit.\n",
    "\t- these functions also permit specifying a new filename for the saved edits, allowing you to save multiple distinct edit sequences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set edit session names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_for_edit = \"demo\"\n",
    "annotation_title = \"demo_annotations\"\n",
    "clip_src_directory = r\"C:\\Users\\chris\\Desktop\\Senior Thesis\\Workspace\"\n",
    "previous_edit_filename = \"demo\"\n",
    "previous_annotation_filename = \"demo_annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit, annotations = setup_editor(\n",
    "    new_edit_title=title_for_edit,\n",
    "    new_annotation_title=annotation_title,\n",
    "\tclips_src_dir=clip_src_directory,\n",
    " \tprevious_edit_filename=previous_edit_filename,\n",
    "  \tprevious_annotation_filename=previous_annotation_filename\n",
    ")\n",
    "for ed in edit.edit_list: print(ed)\n",
    "for ann in annotations: print(ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clip = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous edit from demo.pkl\n",
      "Previous Edit Data Loaded\n",
      "Saving clip annotations to demo_annotations.pkl\n",
      "Annotation Data Loaded\n",
      "--- Beginning Edit ---\n",
      "Full Edit Sequence created\n",
      "Saving current edit to simple_edit.pkl\n",
      "Edit Data Saved\n",
      "File size of simple_edit.pkl: 1116 bytes\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "current_edit = load_edit(title_for_edit)\n",
    "annotations = load_annotations(annotation_title)\n",
    "edit = edit_simple(\n",
    "    current_edit=current_edit,\n",
    "    clips_and_annotations=annotations,\n",
    "    starting_clip=annotations[0],\n",
    "    threshold_frames=5,\n",
    "    cut_frequency_threshold_frames=480,\n",
    "    edit_start_time=0,\n",
    "    strictness_amt=0,\n",
    "    should_save=True\n",
    ")\n",
    "# NOTE: these numbers are entirely arbitrary and should be replaced to fit your needs\n",
    "print(len(edit.edit_list)) # see how many cuts the model recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the result of the above edit\n",
    "for decision in edit.edit_list:\n",
    "    print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clip = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_edit = load_edit(title_for_edit)\n",
    "annotations = load_annotations(annotation_title)\n",
    "edit = edit_complex(\n",
    "    current_edit=current_edit,\n",
    "    clips_and_annotations=annotations,\n",
    "    starting_clip=annotations[0],\n",
    "    threshold_frames=5,\n",
    "    cut_frequency_threshold_frames=0,\n",
    "    edit_start_time=0,\n",
    "    strictness_amt=0,\n",
    "    hold_start_frames=300,\n",
    "    hold_end_frames=200,\n",
    "    should_save=True\n",
    ")\n",
    "# NOTE: these numbers are entirely arbitrary and should be replaced to fit your needs\n",
    "print(len(edit.edit_list)) # see how many cuts the model recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the result of the above edit\n",
    "for decision in edit.edit_list:\n",
    "    print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_edit = load_edit(title_for_edit)\n",
    "annotations = load_annotations(annotation_title)\n",
    "edit = edit_random(\n",
    "    current_edit=current_edit,\n",
    "    clips_and_annotations=annotations,\n",
    "    num_cuts=60,\n",
    "    should_save=True\n",
    ")\n",
    "\n",
    "for e in edit.edit_list[:8]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# view the result of the above edit\n",
    "for decision in edit.edit_list:\n",
    "    print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize a specific frame for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def save_frame_with_face_detection(video_filename, frame_number, output_filename):\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(video_filename)\n",
    "\n",
    "    # Set the frame number\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if frame is successfully read\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame\")\n",
    "        return\n",
    "\n",
    "    # Load the pre-trained face cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Save the frame with face detection borders drawn\n",
    "    cv2.imwrite(output_filename, frame)\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "# Example usage:\n",
    "left_video_filename = \"\"\n",
    "right_video_filename = \"\"\n",
    "frame_number = 1000 # Specify the frame number \n",
    "left_output_filename = left_video_filename[:-4] + '_output_frame_with_detection.png'\n",
    "right_output_filename = right_video_filename[:-4] + '_output_frame_with_detection.png'\n",
    "\n",
    "# save_frame_with_face_detection(left_video_filename, frame_number, left_output_filename)\n",
    "# save_frame_with_face_detection(right_video_filename, frame_number, right_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble Edit into Output Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"random output.mp4\"\n",
    "# edit = load_edit(title_for_edit)\n",
    "final = assemble(edit.edit_list, fps=30, number_of_clips=8, verbose=True, output_video_filename=output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
